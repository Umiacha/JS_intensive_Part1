# Практика: Тестирование

Работа ведётся в папке `tasks/labyrinths`

### Описание

Реализована задача, в которой из файла `tasks/labyrinths/text.txt` читаются 2D массивы, представляющие собой лабиринты.

- 1 - означает, что проход есть
- 0 - что это стена лабиринта

Проговорим алгоритм из главной функции `main`.

Забираем данные по лабиринтам из файла `text.txt` с помощью `getDataFromFile`.

Заводим счетчик **корректных** (pass) и **некорректных** (failed) лабиринтов.

Используем функцию `scan` на каждом лабиринте, чтобы посчитать:

- **кол-во путей лабиринта, начинающихся с пола** (floor). Пол - нижняя часть лабиринта. Путь считается начатым, если в самом низу есть проход.
- **кол-во путей лабиринта, начинающихся с потолка** (ceil). Потолок - верхняя часть лабиринта. Путь считается начатым, если на самом верху есть проход.
- **кол-во изолированных путей** (isolated). То есть, таких путей, которые не соприкасаются с полом и потолком.
- **кол-во путей, проходящих в обе стороны** (both). То есть, таких путей, которые соприкасаются с полом и потолком. Это означает, что по данному пути можно войти и выйти из лабиринта.

Затем смотрим, является ли лабиринт **корректным** или **некорректным**.

Лабиринт является **некорректным**, если `кол-во изолированных путей` + `кол-во путей с потолка` + `кол-во путей с пола` >= `кол-во путей в обе стороны`.

Далее принимается решение, отправлять результаты на сервер или нет.

Если за все прогоны всех лабиринтов, **корректных** > **некорректных**,

- тогда отправляем информацию на сервер, и возвращаем из функции `true`,
- иначе - возвращаем `false`.

Для примера, так выглядит первый лабиринт из файла `text.txt`

```
[
   [0, 0, 0, 0, 0, 0, 0, 1], <- потолок
   [0, 1, 1, 1, 1, 1, 0, 1],
   [0, 1, 0, 0, 0, 1, 0, 1],
   [0, 1, 0, 1, 0, 1, 0, 1],
   [0, 1, 0, 0, 0, 1, 0, 1],
   [0, 1, 0, 0, 0, 0, 0, 1] <- пол
]
```

Функция `scan` для него вернет такой результат `{ ceil: 0, floor: 1, both: 1, isolated: 1 }`.

### Команды

- `npm start` - запустит исполнение файла `tasks/labyrinths/start.js`
- `npm run test` - запустит тесты
- `npm run test:coverage` - запустит тесты с генерацией отчета по покрытию. Отчет смотрим по пути `coverage/lcov-report/index.html`. Анализируйте, какие ветки кода не покрыты и формируйте сценарии тестов

### Что нужно сделать?

Необходимо покрыть тестами все файлы из задания, кроме файла `start.js` (там происходит запуск кода и мокирование сервера).

Не смущайтесь тем, что в задании используются CommonJS модули, и Queue - функция-конструктор, а не класс. Это всё допущения в рамках задания. Мы концентрируем внимание на тестах.

Ответвитесь в ветку `homework`. Прямых требований к коммитам нет. Просто создавайте их с аккуратными частями работы. Не нужно накапливать много правок и пихать их все в один коммит.

В конце работы откройте MR в ветку `master` вашего форка. Если по каким-то причинам что-то пойдет не так, например, не будет запускаться CI, то откроете MR в ветку `master` оригинального репозитория, как было в прошлых заданиях.

#### Общие требования

1. Покрытие тестами, в первую очередь `branch coverage`, а также другие виды `coverage`, каждого файла должно быть выше 80%. Это хороший результат, к которому нужно стремиться в рамках этой работы. Если будет ниже, то ничего страшного и в любом случае работа оценивается по критериям, которые расписаны далее
2. не изменяем существующий код в угоду тестам. Полагаем, что код написан корректно
3. все тесты должны быть написаны с использованием библиотеки `jest`. Никакие другие библиотеки устанавливать не нужно
4. все тесты должны завершаться с успехом. Если проход тестов в CI завершен с ошибкой, ментор не будет брать работу на проверку, пока вы не сделаете тесты "зелеными", так как это важная часть работы
5. все тесты должны соответствовать **критериям хорошего теста**:
   - **защита от багов** - проверяйте значимый функционал для пользователя, в котором не хотелось бы, чтобы появился баг
   - **устойчивость к рефакторингу** - не завязывайтесь в тестах на детали реализации, которые могут меняться при рефакторинге
   - **быстрая обратная связь** - тесты должны проходить за несколько секунд и не блокироваться чем-то непонятным на несколько минут. Также у нас настроен CI, который будет давать быструю обратную связь на уровне контроля кода перед слиянием в главную ветку. Названия тестов должны однозначно давать понять, что сломалось, если тест упал. Так мы быстро понимаем место поломки
   - **простота поддержки** - не пишите сложные тесты. Если ментору будет сложно читать и понимать тест, он попросит вас доработать его
6. в тестах следуем **принципам написания unit тестов** из лекции
   - Одна проверка в тесте
   - Arrange-act-assert
   - Тестируем только публичные методы
   - Даем понятное описание для теста
   - Не проводим сквозное тестирование
   - Тесты не должны быть "плавающими". То есть, должны проходить на каждый запуск
   - Тесты не должны зависеть друг от друга
7. Поведение в файлах **main.js**, **queue.js**, **read.js**, **send.js**, **scan.js** покрыто тестами
   - Для упрощения написания тестов на сценарии в файле **scan.js**, можно не мокать `Queue`. Также для **scan.js** обязательно проверьте различные краевые случаи

